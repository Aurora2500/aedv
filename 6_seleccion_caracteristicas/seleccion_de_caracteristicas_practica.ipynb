{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0582c7",
   "metadata": {},
   "source": [
    "# Práctica de selección de características\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "El objetivo de esta práctica es trabajar con algunas de las técnicas de selección de características estudiadas en  las sesiones teóricas utilizando scikit learn. Debes aplicar los conocimientos adquiridos en las clases de teoría a la resolución de los casos que se proponen y analizar los resultados.\n",
    "\n",
    "## Enunciado\n",
    "En esta práctica trabajaremos la selección de características mediante filtros. Para ello, se presenta un ejemplo completo de selección de características en el caso de predictores categóricos y respuesta categórica. El ejemplo incluye:\n",
    "\n",
    "* Lectura de un dataset\n",
    "* Codificación del dataset\n",
    "* Selección de características usando $\\chi^{2}$\n",
    "* Selección de características usando *mutual information*\n",
    "* Comparación de ambas selecciones usando un modelo de test\n",
    "\n",
    "La tarea que has de realizar consiste en completar los dos casos propuestos en este block de notas de manera análoga al ejemplo presentado.\n",
    "\n",
    "Para ello será necesario estudiar y comprender el caso resuelto y usar la documentación de [scikitlearn](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection) para resolver los dos casos pendientes:\n",
    "* Predictores numéricos, respuesta categórica\n",
    "* Predictores numéricos, respuesta numérica\n",
    "\n",
    "El entregable de esta tarea consistirá en un block de notas, con los siguientes requisitos, completado por el grupo:\n",
    "\n",
    "* **Código** para resolver los casos propuestos\n",
    "* **Explicación del código**: comenta tu código de forma que se entienda cómo funciona.\n",
    "* **Análisis e interpretación de los resultados**: analiza y comenta los resultados y relaciónalos con la teoría. Esto incluye el análisis e interpretación de los resultados del caso resuelto. Emplea gráficas para ilustrar el análisis cuando lo consideres oportuno.\n",
    "\n",
    "Has de entregar un fichero comprimido con **ZIP** (y sólo ZIP) que contenga lo siguiente:\n",
    "* **Block de notas** con el código, los análisis y los comentarios de *todos* los casos (incluido el que está resuelto)\n",
    "* **Directorio con los datos**. Los nombres de ficheros que uses en el block de notas **han de ser relativos** a ese directorio (han de empezar por `'./nombre_directorio'`; ver lectura de fichero del caso resuelto). La idea es que al descomprimir el fichero ZIP se pueda ejecutar el block de notas sin tener que cambiar ni una coma.\n",
    "* **Este trabajo se hace en grupo**, así que basta con que un integrante del grupo haga la entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa88c96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c94cf4",
   "metadata": {
    "heading_collapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Caso resuelto: predictores categóricos, respuesta categórica\n",
    "\n",
    "dataset: `breast-cancer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de6100",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lectura y codificación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c620c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# example of mutual information feature selection for categorical data\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    # format all fields as string\n",
    "    X = X.astype(str)\n",
    "    return X, y\n",
    "\n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    "\n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset('./datos/'+'breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc41f07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_names = ['age', 'menopause', 'tumor-size', 'inv-nodes', \n",
    "                'node-caps','deg-malig', 'breast', 'breast-quad','Class']\n",
    "pd.DataFrame(X_train, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83c28d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_enc, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb34dd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b014c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# feature selection mutual information\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "print(sorted(fs.scores_))\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b797f92",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### $\\chi^{2}$     (chi cuadrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5b87b",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "print(X_train_fs.shape)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d851bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "¿Cómo saber qué características se han seleccionado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c89e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(fs.get_feature_names_out())\n",
    "print(fs.get_support())\n",
    "print(np.nonzero(fs.get_support()))\n",
    "print([column_names[idx] for (idx, item) in enumerate(fs.get_support()) if item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481187a2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Comparación de rendimiento\n",
    "\n",
    "Evaluación de las dos selecciones de características usando como referencia un modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37acb3c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def mi_mutual_info_classif(*args):\n",
    "    score = mutual_info_classif(args[0], args[1], \n",
    "                                discrete_features=True)\n",
    "    return score\n",
    "\n",
    "def select_features(X_train, y_train, X_test, func, k=4):\n",
    "    fs = SelectKBest(score_func=func, k=k)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "l = []\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "for k in range(1, 10):\n",
    "#     print(f'k={k}')\n",
    "\n",
    "    # feature selection\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train_enc, \n",
    "                                                y_train_enc, \n",
    "                                                X_test_enc, chi2, k)\n",
    "    # fit the model using MI\n",
    "    model.fit(X_train_fs, y_train_enc)\n",
    "    # evaluate the model\n",
    "    yhat = model.predict(X_test_fs)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test_enc, yhat)\n",
    "#     print('Accuracy chi2: %.2f' % (accuracy*100))\n",
    "\n",
    "    # feature selection\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train_enc, \n",
    "                                                y_train_enc, \n",
    "                                                X_test_enc,\n",
    "#                                                 mutual_info_classif,\n",
    "                                                mi_mutual_info_classif,\n",
    "                                                k)\n",
    "\n",
    "    # fit the model using mutual information\n",
    "    model.fit(X_train_fs, y_train_enc)\n",
    "    # evaluate the model\n",
    "    yhat = model.predict(X_test_fs)\n",
    "    # evaluate predictions\n",
    "    accuracy_mi = accuracy_score(y_test_enc, yhat)\n",
    "#     print('Accuracy mut. inf.: %.2f' % (accuracy_mi*100))\n",
    "#     print('')\n",
    "    l += [(k, accuracy, accuracy_mi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54258bb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'chi2': [k for _, k, _ in l],\n",
    "                   'mi': [k for _, _, k in l]}, index=range(1,10))\n",
    "from IPython.display import display\n",
    "display(df)\n",
    "\n",
    "df.plot(style='o-', grid=True, figsize=(9,6),\n",
    "        xticks=[i for i in range(1,10)],\n",
    "        title='Precisión vs. número de características', \n",
    "        xlabel='Número de características',\n",
    "        ylabel='accuracy score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e1749",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "## Caso propuesto 1: predictores numéricos, respuesta categórica\n",
    "\n",
    "dataset: `pima-indians-diabetes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee151ba",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "source": [
    "### Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    'npreg',\n",
    "    'glucose',\n",
    "    'diastolic',\n",
    "    'triceps',\n",
    "    'insulin',\n",
    "    'bmi',\n",
    "    'dpf',\n",
    "    'age',\n",
    "    'class'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('./datos/pima-indians-diabetes.csv', names=headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d09431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('class', axis=1), df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97442893",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Estadístico F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ec7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_fstat = SelectKBest(score_func=f_classif, k=4).fit(X_train, y_train)\n",
    "X_train_fs = fs.transform(X_train)\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.bar_label(plt.gca().containers[0], fmt='%1.2f')\n",
    "plt.xticks([i for i in range(len(fs.scores_))], X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aeef94",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mutual information (caso clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_mi = SelectKBest(score_func=mutual_info_classif, k=4).fit(X_train, y_train)\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.bar_label(plt.gca().containers[0], fmt='%1.2f')\n",
    "plt.xticks([i for i in range(len(fs.scores_))], X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef727d2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Modelo con todas las características\n",
    "\n",
    "Usar el modelo `LogisticRegression(solver='liblinear')` y la métrica `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32623125",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Modelo con las 4 mejores características descubiertas con F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca06c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fsf = fs_fstat.transform(X_train)\n",
    "X_test_fsf  = fs_fstat.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear').fit(X_train_fsf, y_train)\n",
    "yhat = model.predict(X_test_fsf)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14f0aa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Modelo con las 4 mejores características descubiertas con *mutual information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fsmi = fs_mi.transform(X_train)\n",
    "X_test_fsmi  = fs_mi.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear').fit(X_train_fsmi, y_train)\n",
    "yhat = model.predict(X_test_fsmi)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92485e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Comparativa de resultados  y comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4d8f7",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "## Caso propuesto 2: predictores numéricos, respuesta numérica\n",
    "\n",
    "En este caso usaremos un dataset sintético, generado con la función `make_regression()` de scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6748cc0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Generación del dataset sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd19e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10,\n",
    "                       noise=0.1, random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,\n",
    "                                                    random_state=1)\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596b7ef",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Regresion (`f_regression()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# feature selection\n",
    "fs = SelectKBest(score_func=f_regression, k=10).fit(X_train, y_train)\n",
    "fs.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca30b3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Mutual information (caso regresión)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c8dbb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Modelo con todas las características\n",
    "\n",
    "Usar el modelo `LinearRegression()` y la métrica `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6bf27",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Modelo con las 10 mejores características obtenidas con la regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb476800",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Modelo con las 10 mejores características obtenidas con *mutual information*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2ab19",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Comparativa de resultados y comentarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "144.5px",
    "width": "383.234375px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "124093b7be10c32076c75f60f415d6def65edeb693f6c465ae4e1e508e9d8137"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
